{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Rapid OCR Realtime\n",
        "## Learn More\n",
        "https://modelscope.ai/models/RapidAI/RapidOCR/ <br>\n",
        "https://github.com/RapidAI/RapidOCR <br>\n",
        "https://docling-project.github.io/docling/examples/rapidocr_with_custom_models/ <br>\n",
        "https://pypi.org/project/rapidocr-onnxruntime <br>\n",
        "https://huggingface.co/spaces/RapidAI/RapidOCR <br>"
      ],
      "metadata": {
        "id": "cyaFq2wsneHb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzZJCtMwfS1J"
      },
      "outputs": [],
      "source": [
        "#@title Install rapidocr_onnxruntime\n",
        "!pip install modelscope\n",
        "!pip install rapidocr_onnxruntime onnxruntime\n",
        "# !pip install onnxruntime-gpu\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Model (We only need a 12.11 MB file, but ModelScope has no option to download single files)\n",
        "import os, shutil\n",
        "from modelscope import snapshot_download\n",
        "\n",
        "save_folder = snapshot_download(\"RapidAI/RapidOCR\")#, cache_dir=\"./rapidocr_models\")\n",
        "src1 = f\"{save_folder}/onnx/PP-OCRv5\"\n",
        "src2 = f\"{save_folder}/onnx/PP-OCRv4\"\n",
        "dst = \"./models\"\n",
        "!rm -rf $dst\n",
        "shutil.copytree(src1, dst, dirs_exist_ok=True)\n",
        "shutil.copytree(src2, dst, dirs_exist_ok=True)\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(f\"Cache DIR : {save_folder}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "txBtE7-vg5P6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from rapidocr_onnxruntime import RapidOCR\n",
        "detection_model = \"/content/models/det/ch_PP-OCRv5_mobile_det.onnx\" #4.6 MB\n",
        "recognition_model = \"/content/models/rec/en_PP-OCRv5_rec_mobile_infer.onnx\" #7.51 MB\n",
        "# text_rotation_classifier_model = \"/content/models/cls/ch_ppocr_mobile_v2.0_cls_infer.onnx\"\n",
        "ocr = RapidOCR(\n",
        "        use_cuda=False,\n",
        "        det_model_path=detection_model,\n",
        "        rec_model_path=recognition_model,\n",
        "        # cls_model_path=text_rotation_classifier_model,\n",
        "        # rec_img_shape=[3, 48, 320],\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "xolbPgPkkZ0f"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "def run_ocr(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    result, _ = ocr(img)\n",
        "\n",
        "    if not result:\n",
        "        return []\n",
        "\n",
        "    data = []\n",
        "    for box, text, score in result:\n",
        "        data.append({\n",
        "            \"text\": text,\n",
        "            \"confidence\": float(round(score, 3))\n",
        "        })\n",
        "\n",
        "    return data\n",
        "\n",
        "image_path= \"/content/test.jpg\"\n",
        "results = run_ocr(image_path)\n",
        "for r in results:\n",
        "    print(r[\"text\"])"
      ],
      "metadata": {
        "id": "p3hGSyiqmyIt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}